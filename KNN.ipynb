{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph1m4bUT8Ehx"
      },
      "source": [
        "# Nearest neighbor for spinal cord injury\n",
        "\n",
        "in this particular project, we are willing to use nearest neighbor algorithm to classify the type of injury that the patient has in the hospital, predicated on the measurements of the shape and orientation of their spine and pelvis. \n",
        "\n",
        "The dataset holds information from 310 patiens. For each patient, there are six measurements (6 independent variables) and only one label (dependent variable), the label has three possible values, `’NO’` (normal), `’DH’` (herniated disk), or `’SL’` (spondilolysthesis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1kTq6BD_8Gt"
      },
      "source": [
        "# 1. Setup notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2fQ2rujANol"
      },
      "source": [
        "We are going to import all the necessary packages particularly for the first section of the project, Notice that we will not import any of Sklearn packages, Because, our main mission is to implement a nearest neighbor classifier manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctyPB_ZEB1ao"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hly8v0KiCEwE"
      },
      "source": [
        "We load our dataset. We slice our data into a training set of 210 patients and testing set of 100 patients. The following array are going to be created after breaking the data into two uneven chunks:\n",
        "\n",
        "\n",
        "*   `’x_train’` : represents the training data's features, has one observation per row.\n",
        "*   `’y_train’` : represents the training data's labels.\n",
        "*   `’x_test’` : represents the testing data's features, has one observation per row.\n",
        "*   `’y_test’` : represents the testing data's labels.\n",
        "\n",
        "We will use the training sets (`x_train`,`y_train`), with nearest neighbor classification to predict the labels for the test data (`x_test`), and will compare the estimated labels against the true ones.\n",
        "\n",
        "The three values associated with the label will be endoded as following : \n",
        "\n",
        "\n",
        "*   0 = `NO`\n",
        "*   1 = `DH`\n",
        "*   2 = `SL`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjfV6bHTHNm3",
        "outputId": "8e8d0ff5-f54c-4f42-dc6d-23115ce22108"
      },
      "source": [
        "# Mount google drive files in google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPRB9kyLIQxT"
      },
      "source": [
        "# load our dataset and attribute to each label a number.\n",
        "labels = [b'NO', b'DH', b'SL']\n",
        "data = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/NN_spine/NN_spine/column_3C.dat', converters={6: lambda s: labels.index(s)})\n",
        "\n",
        "#Seprate features from labels.\n",
        "x = data[:,0:6]\n",
        "y = data[:,6]\n",
        "\n",
        "# Divide the data into training and test set.\n",
        "training_indices = list(range(0,20)) + list(range(40,188)) + list(range(230,310))\n",
        "test_indices = list(range(20,40)) + list(range(188,230))\n",
        "\n",
        "x_train = x[training_indices,:]\n",
        "y_train = y[training_indices]\n",
        "x_test = x[test_indices,:]\n",
        "y_test = y[test_indices]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P7SrQdbbf5H"
      },
      "source": [
        "# 2. Nearest neighbor classifier based on the euclidean distance (L2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPbawlZUbuHM"
      },
      "source": [
        "To compute the nearest neighbor in our dataset, we need to be able to calculate the distance between data points.\n",
        "\n",
        "`Euclidean distance `: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
        "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
        "Often we get red of the square root, and simply compute _squared Euclidean distance_:\n",
        "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
        "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have $\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$.\n",
        "\n",
        "Now we just need to be able to compute squared Euclidean distance. The following function does so.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFnLW0EEe22_",
        "outputId": "87bfee6f-fc9c-4403-f42d-77591d9ec41d"
      },
      "source": [
        "## Build a function that help us to compute distance between two given vectors\n",
        "def squared_dist (x,y):\n",
        "  return np.sqrt(np.sum(np.square(x - y)))\n",
        "\n",
        "# Compute distance between the first and fifth vector in our training set:\n",
        "print ('the actual distance between the first and fifth observation is :', squared_dist(x_train[0,:],x_train[4,:] ))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the actual distance between the first and fifth observation is : 25.069339839732518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZX8Dvv3gmax"
      },
      "source": [
        "# 3. Compute the nearest neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wzSlsy2gwxs"
      },
      "source": [
        "Since we've defined our distance function, we can turn to the nearest neighbor classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs52KSuUhGG_"
      },
      "source": [
        "# take a vector and return the index of its nearest neighbor in training set\n",
        "def find_NN (x_test):\n",
        "  # Compute the distances between the vector x_test and each vector of training set:\n",
        "  for i in range(len(x_test)):\n",
        "    for j in range(len(y_train)): \n",
        "      distances = [squared_dist(x_test, x_train[j,])]\n",
        "  # Get the index of smallest distance\n",
        "  return np.argmin(distances)\n",
        "\n",
        "\n",
        "## Take a vector and return the label of its nearest neighbor in training set\n",
        "def NN_Classifier (x_test):\n",
        "  # Get the index of its nearest neighbor \n",
        "  index = find_NN(x_test)\n",
        "  # Return corresponding class\n",
        "  return y_train[index]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SOJHfpClskt"
      },
      "source": [
        "# 4. Processing the full test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRrfhJMHmC3V"
      },
      "source": [
        "Let's apply our nearest neighbor classifier over the entire test set.\n",
        "\n",
        "Note to classify each test set, our code takes a full pass over each of the 248 training examples. Thus we should not expect testing to be very fast. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQFbjh6Klw7_",
        "outputId": "5f58ae4a-0cb0-4cf4-ea55-48aefac99be4"
      },
      "source": [
        "## Predict on each test data point (and time it!)\n",
        "import time\n",
        "t_before = time.time()\n",
        "test_predictions = [NN_Classifier(x_test)]\n",
        "t_after = time.time()\n",
        "\n",
        "# how much error our classifier makes to predict the class of each observation in test set\n",
        "err_positions = np.not_equal(test_predictions, y_test)\n",
        "error = 1 - float(np.sum(err_positions))/len(y_test)\n",
        "\n",
        "print(\"Error of nearest neighbor classifier: \", error)\n",
        "print(\"Classification time (seconds): \", t_after - t_before)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error of nearest neighbor classifier:  0.32258064516129037\n",
            "Classification time (seconds):  0.16842055320739746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9i1d9VonMzw",
        "outputId": "1c4a52c0-7491-4633-a4a8-5d2b4a721a0d"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "cm"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17,  1,  2],\n",
              "       [10, 10,  0],\n",
              "       [ 0,  0, 22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-0inRUYrBbx"
      },
      "source": [
        "## 5.Simple cross validation \n",
        "We are going to split our data into a training and test set in the ratio of 80:20, We are going to keep 80 percent of our data to train our neareast neighbor and the remaining percentage to assess the performance of our model in predicting the labels of our test data set. We're going to train our model with different values of k, then we're going to capture its accuracy on our test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1A12zEcsqa1"
      },
      "source": [
        "# Import the relevant packages \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJf3EvjTuFSt",
        "outputId": "8aa1ae53-1a67-4aed-8b67-f5be3db1bc86"
      },
      "source": [
        "# Split our data into train and test set \n",
        "X_1, X_test1, y_1, y_test1 = train_test_split(x, y, test_size = 0.20)\n",
        "# Split the train set into cross validation train and cross validation test\n",
        "X_tr, X_cv, y_tr, y_cv = train_test_split(X_1, y_1, test_size = 0.2)\n",
        "\n",
        "for i in range (1,50,2):\n",
        "  #instantiate learning model ()\n",
        "  knn = KNeighborsClassifier(n_neighbors = i)\n",
        "  # fitting the model on cross validation train set\n",
        "  knn.fit(X_tr, y_tr)\n",
        "  # Predicting the labels on cross validation train\n",
        "  pred1 = knn.predict(X_cv)\n",
        "  # Assessing the accuracy of our model\n",
        "  acc = accuracy_score(y_cv, pred1, normalize = True) * float(100)\n",
        "  print('\\n CV ACCURACY FOR K = %d is %d%%' % (i, acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " CV ACCURACY FOR K = 1 is 82%\n",
            "\n",
            " CV ACCURACY FOR K = 3 is 80%\n",
            "\n",
            " CV ACCURACY FOR K = 5 is 78%\n",
            "\n",
            " CV ACCURACY FOR K = 7 is 78%\n",
            "\n",
            " CV ACCURACY FOR K = 9 is 80%\n",
            "\n",
            " CV ACCURACY FOR K = 11 is 88%\n",
            "\n",
            " CV ACCURACY FOR K = 13 is 84%\n",
            "\n",
            " CV ACCURACY FOR K = 15 is 84%\n",
            "\n",
            " CV ACCURACY FOR K = 17 is 84%\n",
            "\n",
            " CV ACCURACY FOR K = 19 is 82%\n",
            "\n",
            " CV ACCURACY FOR K = 21 is 82%\n",
            "\n",
            " CV ACCURACY FOR K = 23 is 82%\n",
            "\n",
            " CV ACCURACY FOR K = 25 is 88%\n",
            "\n",
            " CV ACCURACY FOR K = 27 is 84%\n",
            "\n",
            " CV ACCURACY FOR K = 29 is 84%\n",
            "\n",
            " CV ACCURACY FOR K = 31 is 84%\n",
            "\n",
            " CV ACCURACY FOR K = 33 is 88%\n",
            "\n",
            " CV ACCURACY FOR K = 35 is 90%\n",
            "\n",
            " CV ACCURACY FOR K = 37 is 90%\n",
            "\n",
            " CV ACCURACY FOR K = 39 is 92%\n",
            "\n",
            " CV ACCURACY FOR K = 41 is 90%\n",
            "\n",
            " CV ACCURACY FOR K = 43 is 90%\n",
            "\n",
            " CV ACCURACY FOR K = 45 is 92%\n",
            "\n",
            " CV ACCURACY FOR K = 47 is 88%\n",
            "\n",
            " CV ACCURACY FOR K = 49 is 86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WESVQtCR7Gvb",
        "outputId": "31db67cb-b8cd-4357-f0a5-e24713d86025"
      },
      "source": [
        "# We pick the optimal k at which we get the highest accuracy score\n",
        "## instatiate the learning model (k = 5)\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "## Fitting our model on train data\n",
        "knn.fit(X_1, y_1)\n",
        "## Predicting the response on train data\n",
        "pred2 = knn.predict(X_test1)\n",
        "## Eaxamine the accuracy of our model \n",
        "acc2 = accuracy_score(y_test1, pred2) * float(100)\n",
        "print('\\n The accuracy of our nearest neighbor classifier for k = 5 is : %f%%' %(acc2))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " The accuracy of our nearest neighbor classifier for k = 5 is : 80.645161%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEjj6c3vbUJt"
      },
      "source": [
        "## 6. 10 fold cross validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63cD4NGlbpE0",
        "outputId": "a7bf25ee-f070-49b0-fbcb-d1a34ad367de"
      },
      "source": [
        "# import the important package\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list of odd numbers \n",
        "List = list(range(1,50))\n",
        "Neighbor = list(filter(lambda x : x % 2 != 0, List))\n",
        "\n",
        "# Empty list in which we're going to store cv scores\n",
        "cv_scores = []\n",
        "\n",
        "# Perform 10-fold cross validation \n",
        "for k in Neighbor : \n",
        "  knn = KNeighborsClassifier(n_neighbors = k)\n",
        "  scores = cross_val_score(knn, X_1, y_1, cv = 10, scoring = 'accuracy')\n",
        "  cv_scores.append(scores.mean())\n",
        "\n",
        "# Compute the misclassification error\n",
        "MSE = [1 - x for x in cv_scores]\n",
        "\n",
        "# Find the optimal k \n",
        "optimal_k = Neighbor[MSE.index(min(MSE))]\n",
        "print('\\n The optimal number of neighbor is %d.' % optimal_k)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " The optimal number of neighbor is 7.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}